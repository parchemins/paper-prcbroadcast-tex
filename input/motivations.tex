
\section{Issues and Motivations}
\label{sec:motivations}

Causal broadcast is a communication primitive that allows a process to send
messages to all processes of its distributed system. Message deliveries follow
the happen before relationship. If the sending of a message $m$ precedes the
sending of a message $m'$ then all processes that deliver these two messages
need to deliver $m$ before $m'$. Otherwise they deliver them in any order. Each
process may receive a message multiple times but it delivers it exactly once.

Causal broadcast relies on reliable broadcast. First, it guarantees that all
correct processes eventually receive broadcast messages. Gossiping constitutes
an efficient mean to reliably disseminate messages to large systems. Each
process maintains a partial view considerably smaller than the whole system
membership. When a process broadcasts a message, it sends it to its partial
view; each process that receives such message forwards it to its partial
view. Broadcast messages reach all processes either directly or transitively.

\begin{figure*}
  \begin{center}
    \subfloat[Part A][\label{fig:generalpurgeA}Process~A broadcasts $a$. It expects 
    two copies of the message $a$.]
    {\input{input/figgeneralpurgeA.tex}}
    \hspace{10pt}
    \subfloat[Part B][\label{fig:generalpurgeB}Process~B and Process~C receive
    and deliver $a$. Process~C expected an additional copy of the message $a$
    while Process~B does not.]
    {\input{input/figgeneralpurgeB.tex}}
    \hspace{10pt}
    \subfloat[Part C][\label{fig:generalpurgeC}Process~B and Process~C forward $a$ 
    to their neighbors in a gossip fashion.]
    {\input{input/figgeneralpurgeC.tex}}
    \hspace{10pt}
    \subfloat[Part D][\label{fig:generalpurgeD}Process~A and Process~C receive a copy
    of $a$. Process~C does not expect additional copies of the message $a$. 
    Process~A still expects a copy.]
    {\input{input/figgeneralpurgeD.tex}}
    \hspace{10pt}
    \subfloat[Part E][\label{fig:generalpurgeE}Process~A receives the last 
    awaited copy of the message $a$. It purges its structure from this message.]
    {\input{input/figgeneralpurgeE.tex}}
    \caption{\label{fig:generalpurge}Broadcast that guarantees to deliver 
      messages exactly once using counters.}
  \end{center}
\end{figure*}


\begin{algorithm}
  \input{input/algocounterrbroadcast.tex}
  \caption{\label{algo:counterrbroadcast}R-broadcast at Process $p$ using
    temporary counters.}
\end{algorithm}


Second, reliable broadcast guarantees that each process delivers each broadcast
message exactly once, in spite of multiple receipts that can occur.
Figure~\ref{fig:generalpurge} shows a lightweight implementation that consists
in recording the number of copies expected after the first receipt. When the
expected number of copies falls to zero, the message will never be received
again. Reliable broadcast purges its local structure from this element. In
Figure~\ref{fig:generalpurgeA}, Process~A broadcasts $a$ to Process~B and
Process~C. Since it knows that each process forwards each message exactly once,
it expects to receive 2 copies: one from Process~B, one from Process~C. In
Figure~\ref{fig:generalpurgeB}, Process~B and Process~C receive and deliver
$a$. They both expect another copy of $a$ from Process~C and Process~B
respectively. Since this is their first receipt of $a$, Process~B and Process~C
forward the message to their neighbors. In Figure~\ref{fig:generalpurgeD},
Process~B and Process~C receives the awaited copy from each other. They will
never receive such message again, so they remove it from the set of expected
messages. Process~A receives a copy but does not purge its local structure, for
it still expect an additional copy of the message. It decrements the counter
corresponding to $a$. In Figure~\ref{fig:generalpurgeE}, Process~A finally
receives the last copy of $a$ and purges its structure.

\begin{figure*}
  \begin{center}
    \subfloat[Part A][\label{fig:generalproblemA}Process~A broadcasts $a$.]
    {\input{input/figgeneralproblemA.tex}}
    \hspace{10pt}
    \subfloat[Part B][\label{fig:generalproblemB}Process~C receives,
    delivers, and forwards $a$. It does not expect additional copies.]
    {\input{input/figgeneralproblemB.tex}}
    \hspace{10pt}
    \subfloat[Part C][\label{fig:generalproblemC}Process~B adds Process~C as neighbor.]
    {\input{input/figgeneralproblemC.tex}}    
    \hspace{10pt}
    \subfloat[Part D][\label{fig:generalproblemD}Process~B receives, delivers,
    and forwards $a$. Among others, it sends a copy of $a$ to Process~C.]
    {\input{input/figgeneralproblemD.tex}}    
    \hspace{10pt}
    \subfloat[Part E][\label{fig:generalproblemE}Not only Process~C receives, delivers, 
    and forwards $a$ a second time, but it has cascading effects in the network.
    The expected number of copies becomes inconsistent and may grow unbounded.]
    {\input{input/figgeneralproblemE.tex}}    
    \caption{\label{fig:generalproblem}A broadcast relying on counters may
      deliver messages multiple times leading to inconsistencies.}
  \end{center}
\end{figure*}


Unfortunately, such implementation does not handle dynamic systems where
processes can join, leave, or self-reconfigure their partial view at any
time. Figure~\ref{fig:generalproblem} illustrates the issue. In
Figure~\ref{fig:generalproblemA}, Process~A broadcasts $a$. It sends a copy of
$a$ to its neighbors Process~B and Process~C. In
Figure~\ref{fig:generalproblemB}, Process~C receives $a$ for the first time.  As
consequence, it delivers and forwards it. Since Process~C has only 1 link
towards it, it does not expect additional copies of $a$. In
Figure~\ref{fig:generalproblemC}, Process~B adds Process~C as neighbors. In
Figure~\ref{fig:generalproblemD}, Process~B receives, delivers, and forwards
$a$. Since it added Process~C in its neighborhood, Process~B sends it a copy.
In Figure~\ref{fig:generalproblemE}, Process~C receives $a$ again. Since it did
not keep traces of its former receipt, Process~C believes that it receives $a$
for the first time. Process~C delivers, and forwards $a$ again. In addition, the
number of expected copies changes inconsistently. Processes may deliver messages
multiple times. Messages may travel through the system forever.

Even if this implementation does not work in dynamic systems, it gives the hint
that broadcast can guarantee reliability locally without maintaining costly data
structures summarizing the global state of the system, e.g., using vector
clocks.


% To solve this issue, state-of-the-art protocols maintain a local vector the size
% of which increases linearly with the number of processes that ever broadcast a
% message. They eventually become overcostly in dynamic settings.


In this paper, we exploit and extend \PCBROADCAST to provide a causal broadcast
middleware that is lightweight in terms of local memory consumption, and message
overhead. Table~\ref{table:complexity} shows its complexity. It keeps constant
message overhead and constant delivery execution time while removing the linear
dependency $N$ from the local space complexity. Its overhead in terms of number
of control messages is twice that of \PCBROADCAST.
%% It maintains a local structure that grows and shrinks over time when
%% processes can join, leave, or self-reconfigure their neighborhood over time.
%% \TODO{maybe more details.}
The next section describes the proposed protocol.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../paper.tex"
%%% End:
