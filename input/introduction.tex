 
\section{Introduction}

Causal broadcast constitutes the core communication primitive of many
distributed systems~\cite{hadzilacos1994modular}. Applications such as
distributed social networks~\cite{borthakur2013petabyte}, distributed
collaborative software~\cite{heinrich2012exploiting,nedelec2016crate}, or
distributed data
stores~\cite{bailis2013bolton,bravo2017saturn,demers1987epidemic,lloyd2011cops,shapiro2011comprehensive}
use causal broadcast to ensure consistency criteria.  Causal broadcast ensures
reliable receipt of broadcast messages, and exactly-once delivery following
Lamport's happen before relationship~\cite{lamport1978time}. When Alice comments
Bob's picture, nobody sees Alice's comment without Bob's picture, and nobody
sees multiple occurrences of Alice's comment or Bob's picture.
% If the sending of a message $m$ precedes the sending of a message $m'$ then all
% processes that deliver these two messages need to deliver $m$ before
% $m'$. Otherwise they deliver them in any order.

In large and dynamic systems comprising from hundreds to millions of processes,
no process can afford to maintain an up-to-date knowledge of the full
membership~\cite{birman1999bimodal,demers1987epidemic}. Instead, each process
builds a partial view of neighbors to communicate
with~\cite{jelasity2007gossip}. Gossiping exploits these neighborhoods to
efficiently broadcast a message to all processes. To broadcast a message, a
process sends the message to its neighbors; each process receiving such message
forwards it to its own neighbors. Processes receive the message either directly
or transitively. 


% In static systems where processes cannot join, leave, or self-reconfigure their
% neighborhood, the local structure that ensures exactly once delivery is
% lightweight.  Since each process forwards each message exactly once, each
% process knows that it will receive a number of copies of the original message
% equal to the number of their incoming links. Once it received that many copies,
% it safely purges its local structure from this message. It will never receive
% this message again.  However, in dynamic systems, when a process adds a neighbor
% to its partial view, the latter does not know if it should expect another
% message copy from this new incoming link. It may cause multiple deliveries of a
% same message.

Processes may receive a broadcast message multiples times from different
sources.  To forbid multiple delivery, state-of-the-art protocols constrain the
dissemination topology to tree or ring that ensures single receipt hence single
delivery~\cite{bravo2017saturn,raynal2013distributed}. However, such topologies
are difficult to maintain in dynamic systems subject to
failures~\cite{krasikova2016hashtable}. To forbid multiple delivery,
state-of-the-art protocols maintains local structure to identify and discard
additional copies of an original message at receipt. They either rely on
physical clocks~\cite{cachin2011introduction,demers1987epidemic} or on vectors
of logical clocks~\cite{malkhi2007concise,mukund2014optimized}. Physical clocks
allow to remove obsolete control information over time. However, they may remove
useful information leading to multiple deliveries with cascading effects in the
system. Vector clocks forbid multiple delivery in dynamic systems. However,
their size increases linearly and monotonically with the number of processes
that ever broadcast a message. They eventually become inefficient, for processes
cannot safely reclaim entries without running an overcostly distributed garbage
collecting protocol~\cite{abdullahi1998garbage}.


% \TODO{We do reliable broadcast on top of causal broadcast. Did not make sense
%   before because the cost of causal broadcast was too high. Now that it's cheap,
%   we use it to enable reliability at marginal cost.}

% State-of-the-art causal broadcasts (\REF) reuse this vector of clocks. Each
% message piggybacks such vector to ensure their causal delivery. A recent causal
% broadcast (\REF) alleviates processes from the need for piggybacking vectors in
% messages. However, it still requires to maintain the local vector to ensure that
% it delivers each message exactly once.

\begin{table}
  \begin{center}
    \caption{\label{table:complexity} Complexity of broadcast algorithms at each
      process. $N$ the number of processes that ever broadcast a message. $P$
      the number of processes in the system. $W$ the number of messages received
      but not delivered yet. $Q_i$ is the number of processes in the in-view. $M$
      is the number of messages already delivered that should be received again
      from at least one process in $Q_i$.}
    \input{input/tablecomplexity.tex}
  \end{center}
\end{table}

In this paper, we introduce an implementation of causal broadcast that removes
the last monotonic upper bound on space complexity without constraining the
topology.  Our contribution is threefold:
\begin{itemize}[leftmargin=*]
\item We provide the scientific problem to solve: locally identifying processes
  that will broadcast or forward a message while discarding obsolete control
  information about messages that will never be received again. Assuming causal
  order, we prove that each process can build such knowledge even in dynamic
  systems where processes join, leave, or self-reconfigure their neighborhood at
  any time.
\item Our implementation provides an original tradeoff that actually depends on
  the system and its current usage. Quiescent systems suffer from no
  overhead. Table~\ref{table:complexity} shows that it keeps constant size
  overhead on messages while its space consumption is non-monotonic. It exploits
  causal order to purge all and only obsolete control information. This costs
  only few lightweight control messages in dynamic systems.  Our implementation
  does not maintain any specific topology. However, the number of control
  messages depends on routing capabilities of the system and its dynamicity. For
  instance, gossip-based peer-sampling
  protocols~\cite{jelasity2007gossip,jelasity2009tman,nedelec2017adaptive} need
  only 8 control messages per added link during periodic shuffles.
\item Our experiments highlights the space consumed by our protocol in dynamic
  systems with varying latency. It confirms that the proposed approach scales
  with the system settings instead of past broadcast messages. Processes
  actually pay at the height of their current use.
\end{itemize}
Our implementation offers an advantageous tradeoff that makes causal broadcast a
lightweight and efficient middleware in large and dynamic systems. This tradeoff
even makes a lightweight and efficient implementation of reliable broadcast.

The rest of this paper is organized as follows. 
% Section~\ref{sec:motivations}
% shows the issue and motivates this work.
Section~\ref{sec:proposal} presents the model, the problem, the proposed causal
broadcast along with its corresponding proofs and complexity
analysis. Section~\ref{sec:experimentation} shows the
experiments. Section~\ref{sec:relatedwork} reviews related work. We conclude in
Section~\ref{sec:conclusion}.


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../paper"
%%% End:
